{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from random import random\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, w = [], out = None, delta = 0.0):\n",
    "        self.weights = w\n",
    "        self.output = out\n",
    "        self.delta = delta\n",
    "    def __str__(self):\n",
    "        return \"weights: \" + str(self.weights) + \", output: \" + str(self.output) + \", delta: \" + str(self.delta)\n",
    "    def __repr__(self):\n",
    "        return \"weights: \" + str(self.weights) + \", output: \" + str(self.output) + \", delta: \" + str(self.delta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate(input, weights): \n",
    "    result = 0.0\n",
    "    for i in range(0, len(input)):\n",
    "        result += input[i] * weights[i]\n",
    "    result += weights[len(input)]\n",
    "    return result\n",
    "\n",
    "\n",
    "#neuron transfer\n",
    "from math import exp\n",
    "def transfer(value):\n",
    "    if (activationType == \"identity\"):\n",
    "        return value\n",
    "    elif (activationType == \"Sigmoid\"):\n",
    "        return 1.0 / (1.0 + exp(-value))\n",
    "    \n",
    "#neuron computation/activation\n",
    "def forwardPropagation(net, inputs):    \n",
    "    for layer in net:\n",
    "        newInputs = []\n",
    "        for neuron in layer:\n",
    "            activation = activate(inputs, neuron.weights)\n",
    "            neuron.output = transfer(activation)\n",
    "            newInputs.append(neuron.output)\n",
    "        inputs = newInputs\n",
    "    return inputs\n",
    "\n",
    "#inverse transfer of a neuron\n",
    "def transferInverse(val):\n",
    "    if (activationType == \"identity\"):\n",
    "        return val\n",
    "    elif (activationType == \"Sigmoid\"):\n",
    "        return val * ( 1 - val)\n",
    "\n",
    "#error propagation\n",
    "def backwardPropagation(net, expected):\n",
    "    for i in range(len(net) - 1, 0, -1):\n",
    "        crtLayer = net[i]\n",
    "        errors = []\n",
    "        if (i == len(net) - 1): #last layer\n",
    "            for j in range(0, len(crtLayer)):\n",
    "                crtNeuron = crtLayer[j]\n",
    "                errors.append(expected[j] - crtNeuron.output)\n",
    "        else:   #hidden layers\n",
    "            for j in range(0, len(crtLayer)):\n",
    "                crtError = 0.0\n",
    "                nextLayer = net[i + 1]\n",
    "                for neuron in nextLayer:\n",
    "                    crtError += neuron.weights[j] * neuron.delta\n",
    "                errors.append(crtError)\n",
    "        for j in range(0, len(crtLayer)):\n",
    "            crtLayer[j].delta = errors[j] * transferInverse(crtLayer[j].output)        \n",
    "                        \n",
    "#change the weights            \n",
    "def updateWeights(net, example, learningRate):\n",
    "    for i in range(0, len(net)):    #for each layer\n",
    "        inputs = example[:-1]\n",
    "        if (i > 0): #hidden layers or output layer\n",
    "            inputs = [neuron.output for neuron in net[i - 1]]   #computed values of precedent layer\n",
    "        for neuron in net[i]:   #update weight of all neurons of the current layer\n",
    "            for j in range(len(inputs)):\n",
    "                neuron.weights[j] += learningRate * neuron.delta * inputs[j]\n",
    "            neuron.weights[-1] += learningRate * neuron.delta \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network training\n",
    "def trainingMLP(net, data, outputs, learningRate, noEpochs):\n",
    "    for epoch in range(0, noEpochs):\n",
    "        sumError = 0.0\n",
    "        for inputs, expected in zip(data, outputs):\n",
    "            computedOutputs = forwardPropagation(net, inputs)\n",
    "            crtErr = sum([(expected[i] - computedOutputs[i]) ** 2 for i in range(0, len(expected))])\n",
    "            sumError += crtErr\n",
    "            backwardPropagation(net, expected)\n",
    "            updateWeights(net, inputs, learningRate)\n",
    "         \n",
    "# network evaluation\n",
    "def evaluatingMLP(net, data):\n",
    "    computedOutputs = []\n",
    "    for inputs in data:\n",
    "        computedOutput = forwardPropagation(net, inputs[:-1])  \n",
    "        computedOutputs.append(computedOutput[0])       \n",
    "    return computedOutputs\n",
    "\n",
    "def computePerformanceRegression(computedOutputs, realOutputs):\n",
    "    error = sum([(computedOutputs[i] - realOutputs[i]) ** 2 for i in range(len(computedOutputs))])\n",
    "    return error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "train SRE:  [0.78354864]\ntest SRE:  [1.68076653]\n"
    }
   ],
   "source": [
    "PROBLEMTYPE = 'regression'\n",
    "\n",
    "# f(x,y,z) = w0 + w1 * x + w2 * y + w3 * z \n",
    "\n",
    "regressionDataTrain = [[0.5, 0.05, 0.1, 0.95], \n",
    "                       [0.5, 0.1, 0.5, 0.6], \n",
    "                       [0.1, 0.2, 0.2, 0.2], \n",
    "                       [0.2, 0.3, 0.1, 0.6], \n",
    "                       [0.3, 0.3, 0.1, 0.8]]\n",
    "regressionDataValidation = [[0.2, 0.4, 0.1, 0.7], \n",
    "                      [0.2, 0.3, 0.5, 0.2], \n",
    "                      [0.3, 0.3, 0.7, 0.2]]\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "inputTrain = np.array([line[:-1] for line in regressionDataTrain])\n",
    "outputTrain = np.array([[line[-1]] for line in regressionDataTrain])\n",
    " \n",
    "inputValidation = np.array([line[:-1] for line in regressionDataValidation])\n",
    "outputValidation = np.array([[line[-1]] for line in regressionDataValidation])\n",
    "\n",
    "activationType = 'identity'\n",
    "# activationType = 'Sigmoid'\n",
    "learningRate = 0.001\n",
    "noEpochs = 100\n",
    "\n",
    "noInputs = len(inputTrain[0])\n",
    "noOutputs = 1\n",
    "\n",
    "#initialisation of the weights for each neuron of all the layers (a hidden layer of 2 neurons and an output layer)\n",
    "noHiddenNeurons = 2\n",
    "net = []    \n",
    "\n",
    "hiddenLayer = [Neuron([ random() for i in range(noInputs + 1)]) for h in range(noHiddenNeurons)]  \n",
    "# hiddenLayer = [Neuron([ 0.0 for i in range(noInputs + 1)]) for h in range(noHiddenNeurons)]  \n",
    "net.append(hiddenLayer)\n",
    "\n",
    "outputLayer = [Neuron([ random() for i in range(noHiddenNeurons + 1)]) for o in range(noOutputs)]  \n",
    "# outputLayer = [Neuron([ 0.0 for i in range(noHiddenNeurons + 1)]) for o in range(noOutputs)]  \n",
    "net.append(outputLayer)\n",
    "\n",
    "\n",
    "# network training\n",
    "trainingMLP(net, inputTrain, outputTrain, learningRate, noEpochs)\n",
    "\n",
    "# network testing \n",
    "computedOutputTrain = evaluatingMLP(net, inputTrain)\n",
    "print(\"train SRE: \", computePerformanceRegression(computedOutputTrain, outputTrain))\n",
    "        \n",
    "computedOutputValidation = evaluatingMLP(net, inputValidation)\n",
    "print(\"validation SRE: \", computePerformanceRegression(computedOutputValidation, outputValidation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "TOOL, train SRE:  [0.65770754]\nTOOL, test SRE:  [0.17500994]\n"
    }
   ],
   "source": [
    "from sklearn import neural_network\n",
    "ann = neural_network.MLPRegressor((2,), activation = activationType, solver = 'sgd', learning_rate_init = learningRate, max_iter = noEpochs)\n",
    "ann.fit(inputTrain, outputTrain)\n",
    "computedOutputs = ann.predict(inputTrain)\n",
    "print(\"TOOL, train SRE: \", computePerformanceRegression(computedOutputs, outputTrain))    \n",
    "        \n",
    "\n",
    "computedOutputs = ann.predict(inputValidation)\n",
    "print(\"TOOL, validation SRE: \", computePerformanceRegression(computedOutputs, outputValidation))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37264bitmyenvvenv9d2ef12a62c64e369825be189b104135",
   "display_name": "Python 3.7.2 64-bit ('myenv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}